{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "VJNZRmlAE7LM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python import control_flow_ops\n",
        "import time, os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tflearn.data_preprocessing import ImagePreprocessing\n",
        "from tflearn.data_augmentation import ImageAugmentation\n",
        "from tflearn.data_utils import to_categorical, shuffle\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.estimator import regression\n",
        "from tflearn import DNN\n",
        "import tflearn\n",
        "import cv2\n",
        "tf.reset_default_graph()\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "IMG_SIZE = 50\n",
        "\n",
        "def plot_img(im):\n",
        "    im_gray = rgb2gray(im)\n",
        "    plt.figure(figsize=(10,4))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(im)\n",
        "    plt.axis('off')\n",
        "    plt.title('Original Image')\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(im_gray, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title('Grayscale Image')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def load_data(path):\n",
        "    images, labels = [], []\n",
        "    folders = os.listdir(path)\n",
        "    for i in range(len(folders)):\n",
        "        dir_img = os.path.join(path, folders[i])\n",
        "        labels.append(i)\n",
        "        for j in os.listdir(dir_img):\n",
        "            img = os.path.join(dir_img, j)\n",
        "            img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
        "            try:\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "                images.append(np.array(img))\n",
        "            except:\n",
        "                continue\n",
        "    return np.array(images, dtype=np.float64), labels\n",
        "if \"learning-neural-networks\" not in os.listdir():\n",
        "  ! git clone https://github.com/agusmdev/learning-neural-networks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nAjFFIQJE7LQ",
        "colab_type": "code",
        "outputId": "9d65b423-f841-4990-a79c-c826af12aaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "if \"test-data\" not in os.listdir():\n",
        "  !git clone https://github.com/agusmdev/test-data\n",
        "\n",
        "images, labels = load_data(\"./learning-neural-networks/datasets/flowers/\")\n",
        "\n",
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4323, 50, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "1Bn9JGFsE7LX",
        "colab_type": "code",
        "outputId": "f08c8f09-422a-42f1-b82f-35d8205894f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Process our TF dataset \"\"\"\n",
        "# split our tf set in a test and training part\n",
        "\n",
        "X, X_test, Y, Y_test = train_test_split(images, labels, test_size=0.1, random_state=42)\n",
        "X, Y = shuffle(X, Y)\n",
        "\n",
        "# encode our labels\n",
        "Y = to_categorical(Y, 5)\n",
        "Y_test = to_categorical(Y_test, 5)\n",
        "X = X.reshape([-1, IMG_SIZE, IMG_SIZE, 1])\n",
        "X_test = X_test.reshape([-1, IMG_SIZE, IMG_SIZE, 1])\n",
        "\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3890, 50, 50, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "oeEzPAINE7Lb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf_img_prep = ImagePreprocessing()\n",
        "tf_img_prep.add_featurewise_zero_center()\n",
        "tf_img_prep.add_featurewise_stdnorm()\n",
        "\n",
        "\n",
        "# Randomly create extra image data by rotating and flipping images\n",
        "tf_img_aug = ImageAugmentation()\n",
        "tf_img_aug.add_random_flip_leftright()\n",
        "tf_img_aug.add_random_rotation(max_angle=30.)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qaKOMxrfE7Le",
        "colab_type": "code",
        "outputId": "4c138715-b19b-4123-c71a-19c23a319142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "cell_type": "code",
      "source": [
        "#tf.reset_default_graph()\n",
        "# Convolutional network building\n",
        "network = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1],\n",
        "                     data_preprocessing=tf_img_prep,\n",
        "                     data_augmentation=tf_img_aug)\n",
        "network = conv_2d(network, 32, 3, activation='relu')\n",
        "network = max_pool_2d(network, 2)\n",
        "network = conv_2d(network, 64, 3, activation='relu')\n",
        "network = conv_2d(network, 128, 3, activation='relu')\n",
        "network = max_pool_2d(network, 2)\n",
        "network = fully_connected(network, 1024, activation='relu')\n",
        "network = dropout(network, 0.8)\n",
        "network = fully_connected(network, 5, activation='softmax')\n",
        "network = regression(network, optimizer='adam',\n",
        "                     loss='categorical_crossentropy',\n",
        "                     learning_rate=0.001)\n",
        "\n",
        "# Train using classifier\n",
        "model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='model.tfl.ckpt')\n",
        "model.fit(X, Y, n_epoch=300, shuffle=True, validation_set=(X_test, Y_test),\n",
        "          show_metric=True, batch_size=96, run_id='flowers_cnn2', snapshot_epoch=True)\n",
        "model.save(\"flowers_cnn2.model\")\n",
        "#model.load(\"flowers_cnn.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 12299  | total loss: \u001b[1m\u001b[32m0.02318\u001b[0m\u001b[0m | time: 2.095s\n",
            "| Adam | epoch: 300 | loss: 0.02318 - acc: 0.9931 -- iter: 3840/3890\n",
            "Training Step: 12300  | total loss: \u001b[1m\u001b[32m0.02274\u001b[0m\u001b[0m | time: 3.151s\n",
            "| Adam | epoch: 300 | loss: 0.02274 - acc: 0.9938 | val_loss: 2.01712 - val_acc: 0.5820 -- iter: 3890/3890\n",
            "--\n",
            "INFO:tensorflow:/content/model.tfl.ckpt-12300 is not in all_model_checkpoint_paths. Manually adding it.\n",
            "INFO:tensorflow:/content/flowers_cnn2.model is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZMoUYFE1E7Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "#TEST_DIR = \"./learning-neural-networks/datasets/flowers/tulip\"\n",
        "TEST_DIR = \"./test-data/flowers_data/\"\n",
        "def process_test_data():\n",
        "    testing_data = []\n",
        "    for img in tqdm(os.listdir(TEST_DIR)):\n",
        "        path = os.path.join(TEST_DIR,img)\n",
        "        img_num = img.split('.')[0]\n",
        "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        testing_data.append([np.array(img, dtype=np.float32), img_num])\n",
        "        \n",
        "    shuffle(testing_data)\n",
        "    np.save('test_data.npy', testing_data)\n",
        "    return testing_data\n",
        "  \n",
        "labels = [\"sunflower\", \"tulip\", \"rose\", \"dandelion\", \"daisy\"] \n",
        "test_data = process_test_data()\n",
        "fig=plt.figure()\n",
        "\n",
        "for num,data in enumerate(test_data):\n",
        "    \n",
        "    img_num = data[1]\n",
        "    img_data = data[0]\n",
        "    \n",
        "    y = fig.add_subplot(3,4,num+1)\n",
        "    orig = img_data\n",
        "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
        "    #model_out = model.predict([data])[0]\n",
        "    model_out = model.predict([data])[0]\n",
        "    \n",
        "    str_label = labels[np.argmax(model_out)]\n",
        "\n",
        "        \n",
        "    y.imshow(orig,cmap='gray')\n",
        "    plt.title(str_label)\n",
        "    y.axes.get_xaxis().set_visible(False)\n",
        "    y.axes.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8P0X9CtI5xJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_path = './test-data/flowers_data/rose.jpg'\n",
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "img = np.array(cv2.resize(img, (IMG_SIZE, IMG_SIZE)), dtype=np.float64)\n",
        "#img = img.reshape([IMG_SIZE, IMG_SIZE, 1])\n",
        "img = img.reshape(IMG_SIZE, IMG_SIZE, -1)\n",
        "#plot_img(img)\n",
        "img.shape\n",
        "#X_test[0].shape\n",
        "# img.shape\n",
        "# # Predict\n",
        "predicted = model.predict([img])\n",
        "predicted\n",
        "\n",
        "predicciones = np.array(model.predict(X_test)).argmax(axis=1)\n",
        "correctas = Y_test.argmax(axis=1)\n",
        "certeza = np.mean(predicciones == correctas, axis=0)\n",
        "print(\"La certeza es de: \", certeza)\n",
        "\n",
        "print(\"\\n\\n\\nPrediccion:\")\n",
        "# Check the result.\n",
        "print(labels[np.argmax(predicted[0])])\n",
        "print(\"\\nProbabilidades: \"+str(np.around(predicted[0]*100, decimals=3)))\n",
        "print(\"\\n\\n\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ksXjZW2LE7Lm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICe3jsXfE7Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}